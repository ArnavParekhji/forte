"""
The reader that reads Ontonotes data into Datapacks.
"""
import os
import codecs
from typing import DefaultDict, List, Optional, Iterator, Tuple
from collections import defaultdict
from nlp.pipeline.data.readers import MonoFileReader
from nlp.pipeline.data.data_pack import DataPack
from nlp.pipeline.data.ontology import ontonotes_ontology

__all__ = [
    "OntonotesReader",
]


class OntonotesReader(MonoFileReader):
    """:class:`OntonotesReader` is designed to read in the English OntoNotes
    v5.0 data in the format used by the CoNLL 2011/2012 shared tasks. To use
    this Reader, you must follow the instructions provided `here (v12 release):
    <http://cemantix.org/data/ontonotes.html>`_:, which will allow you to
    download the CoNLL style annotations for the OntoNotes v5.0 release
    â€“ LDC2013T19.tgz obtained from LDC.

    Args:
        lazy (bool, optional): The reading strategy used when reading a
            dataset containing multiple documents. If this is true,
            ``dataset_iterator()`` will return an object whose ``__iter__``
            method reloads the dataset each time it's called. Otherwise,
            ``dataset_iterator()`` returns a list.
    """
    def __init__(self, lazy: bool = True):
        super().__init__(lazy)
        self.ontology = ontonotes_ontology

    @staticmethod
    def dataset_path_iterator(dir_path: str) -> Iterator[str]:
        """
        An iterator returning file_paths in a directory containing
        CoNLL-formatted files.
        """
        for root, _, files in os.walk(dir_path):
            for data_file in files:
                if data_file.endswith("gold_conll"):
                    yield os.path.join(root, data_file)

    def _read_document(self, file_path: str) -> DataPack:
        doc = codecs.open(file_path, "r", encoding="utf8")

        text = ""
        offset = 0
        has_rows = False

        speaker = part_id = document_id = None
        sentence_begin = 0

        # auxiliary structures
        current_entity_mention: Optional[Tuple[int, str]] = None
        verbal_predicates: List[str] = []

        current_pred_arg: List[Optional[Tuple[str, str]]] = []
        verbal_pred_args: List[List[Tuple[str, str]]] = []

        groups: DefaultDict[int, List[str]] = defaultdict(list)
        coref_stacks: DefaultDict[int, List[int]] = defaultdict(list)

        for line in doc:
            line = line.strip()

            if line.startswith("#end document"):
                break

            if line != "" and not line.startswith("#"):
                conll_components = line.split()
                document_id = conll_components[0]
                part_id = int(conll_components[1])
                word = conll_components[3]
                pos_tag = conll_components[4]
                lemmatised_word = conll_components[6]
                framenet_id = conll_components[7]
                word_sense = conll_components[8]
                speaker = conll_components[9]
                entity_label = conll_components[10]
                pred_labels = conll_components[11:-1]

                word_begin = offset
                word_end = offset + len(word)

                # add tokens
                kwargs_i = {"pos_tag": pos_tag, "sense": word_sense}
                token = self.ontology.Token(
                    self.component_name, word_begin, word_end
                )
                token.set_fields(**kwargs_i)
                self.current_datapack.add_entry(token)

                # add entity mentions
                current_entity_mention = self._process_entity_annotations(
                    entity_label, word_begin, word_end, current_entity_mention
                )

                # add predicate mentions
                if lemmatised_word != "-":
                    word_is_verbal_predicate = any(
                        ["(V" in x for x in pred_labels]
                    )
                    kwargs_i = {
                        "framenet_id": framenet_id,
                        "pred_lemma": lemmatised_word,
                        "pred_type": "verb" if word_is_verbal_predicate
                                     else "other"
                    }
                    pred_mention = self.ontology.PredicateMention(
                        self.component_name, word_begin, word_end
                    )
                    pred_mention.set_fields(**kwargs_i)
                    pred_mention_id = self.current_datapack.add_entry(
                        pred_mention
                    )

                    if word_is_verbal_predicate:
                        verbal_predicates.append(pred_mention_id)

                if not verbal_pred_args:
                    current_pred_arg = [None for _ in pred_labels]
                    verbal_pred_args = [[] for _ in pred_labels]

                # add predicate arguments
                self._process_pred_annotations(
                    conll_components[11:-1],
                    word_begin,
                    word_end,
                    current_pred_arg,
                    verbal_pred_args,
                )

                # add coreference mentions
                self._process_coref_annotations(
                    conll_components[-1],
                    word_begin,
                    word_end,
                    coref_stacks,
                    groups,
                )

                text += word + " "
                offset = word_end + 1
                has_rows = True

            else:
                if not has_rows:
                    continue

                # add predicate links in the sentence
                for predicate, pred_arg in zip(verbal_predicates,
                                               verbal_pred_args):
                    for arg in pred_arg:
                        kwargs_i = {
                            "arg_type": arg[1],
                            "parent": predicate,
                            "child": arg[0],
                        }
                        link = self.ontology.PredicateLink(self.component_name)
                        link.set_fields(**kwargs_i)
                        self.current_datapack.add_entry(link)

                verbal_predicates = []
                current_pred_arg = []
                verbal_pred_args = []

                # add sentence

                kwargs_i = {"speaker": speaker, "part_id": part_id}
                sent = self.ontology.Sentence(
                    self.component_name, sentence_begin, offset - 1
                )
                sent.set_fields(**kwargs_i)
                self.current_datapack.add_entry(sent)

                sentence_begin = offset

                has_rows = False

        # group the coreference mentions in the whole document
        for group_id, mention_list in groups.items():
            kwargs_i = {"coref_type": group_id}
            group = self.ontology.CoreferenceGroup(self.component_name)
            group.set_fields(**kwargs_i)
            group.add_members(mention_list)
            self.current_datapack.add_entry(group)

        kwargs_i = {"doc_id": document_id}
        self.current_datapack.set_meta(**kwargs_i)
        self.current_datapack.text = text

        doc.close()
        return self.current_datapack

    def _process_entity_annotations(self,
                                    label: str,
                                    word_begin: int,
                                    word_end: int,
                                    current_entity_mention: Tuple[int, str],
                                    ) -> Tuple[int, str]:

        ner_type = label.strip("()*")

        if "(" in label:
            # Entering into a span for a particular ner.
            current_entity_mention = (word_begin, ner_type)
        if ")" in label:
            # Exiting a span, add and then reset the current span.
            kwargs_i = {"ner_type": current_entity_mention[1]}
            entity = self.ontology.EntityMention(
                self.component_name, current_entity_mention[0], word_end
            )
            entity.set_fields(**kwargs_i)
            self.current_datapack.add_entry(entity)

            current_entity_mention = None

        return current_entity_mention

    def _process_pred_annotations(
            self,
            labels: List[str],
            word_begin: int,
            word_end: int,
            current_pred_arg: List[Optional[Tuple[int, str]]],
            verbal_pred_args: List[List[Tuple[str, str]]],
    ) -> None:

        for label_index, label in enumerate(labels):

            arg_type = label.strip("()*")
            if arg_type == "V":
                continue

            if "(" in label:
                # Entering into a span
                current_pred_arg[label_index] = (word_begin, arg_type)
            if ")" in label:
                # Exiting a span
                arg_begin = current_pred_arg[label_index][0]
                arg_type = current_pred_arg[label_index][1]

                pred_arg = self.ontology.PredicateArgument(
                    self.component_name, arg_begin, word_end
                )
                pred_arg_id = self.current_datapack.add_entry(pred_arg)

                verbal_pred_args[label_index].append((pred_arg_id, arg_type))
                current_pred_arg[label_index] = None

    def _process_coref_annotations(
            self,
            label: str,
            word_begin: int,
            word_end: int,
            coref_stacks: DefaultDict[int, List[int]],
            groups: DefaultDict[int, List[str]],
    ) -> None:

        if label == "-":
            return
        for segment in label.split("|"):
            # The conll representation of coref spans allows spans to overlap.
            if segment[0] == "(":
                if segment[-1] == ")":
                    # The span begins and ends at this word (single word span).
                    group_id = int(segment[1:-1])

                    coref_mention = self.ontology.CoreferenceMention(
                        self.component_name, word_begin, word_end
                    )
                    coref_mention_id = self.current_datapack.add_entry(
                        coref_mention
                    )

                    groups[group_id].append(coref_mention_id)
                else:
                    # The span is starting, so we record the index of the word.
                    group_id = int(segment[1:])
                    coref_stacks[group_id].append(word_begin)
            else:
                # The span for this id is ending, but not start at this word.
                group_id = int(segment[:-1])
                start = coref_stacks[group_id].pop()
                coref_mention = self.ontology.CoreferenceMention(
                    self.component_name, start, word_end
                )
                coref_mention_id = self.current_datapack.add_entry(
                    coref_mention
                )

                groups[group_id].append(coref_mention_id)

    def _record_fields(self):
        self.current_datapack.record_fields(
            ["speaker", "part_id", "span"],
            self.ontology.Sentence.__name__,
            self.component_name,
        )
        self.current_datapack.record_fields(
            ["sense", "pos_tag", "span"],
            self.ontology.Token.__name__,
            self.component_name,
        )
        self.current_datapack.record_fields(
            ["ner_type", "span"],
            self.ontology.EntityMention.__name__,
            self.component_name,
        )
        self.current_datapack.record_fields(
            ["pred_lemma", "pred_type", "span", "framenet_id"],
            self.ontology.PredicateMention.__name__,
            self.component_name,
        )
        self.current_datapack.record_fields(
            ["span"],
            self.ontology.PredicateArgument.__name__,
            self.component_name,
        )
        self.current_datapack.record_fields(
            ["parent", "child", "arg_type"],
            self.ontology.PredicateLink.__name__,
            self.component_name,
        )
        self.current_datapack.record_fields(
            ["span"],
            self.ontology.CoreferenceMention.__name__,
            self.component_name,
        )
        self.current_datapack.record_fields(
            ["coref_type", "members"],
            self.ontology.CoreferenceGroup.__name__,
            self.component_name,
        )
